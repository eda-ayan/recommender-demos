{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "# set the environment path to find Recommenders\r\n",
        "import sys\r\n",
        "import pyspark\r\n",
        "from pyspark.ml.recommendation import ALS\r\n",
        "import pyspark.sql.functions as F\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark.sql.types import StructType, StructField\r\n",
        "from pyspark.sql.types import StringType, FloatType, IntegerType, LongType\r\n",
        "\r\n",
        "from recommenders.utils.timer import Timer\r\n",
        "from recommenders.datasets import movielens\r\n",
        "from recommenders.utils.notebook_utils import is_jupyter\r\n",
        "from recommenders.datasets.spark_splitters import spark_random_split\r\n",
        "from recommenders.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\r\n",
        "from recommenders.utils.spark_utils import start_or_get_spark\r\n",
        "\r\n",
        "print(\"System version: {}\".format(sys.version))\r\n",
        "print(\"Spark version: {}\".format(pyspark.__version__))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "System version: 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \n[GCC 7.3.0]\nSpark version: 3.1.2\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1634740620911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# top k items to recommend\r\n",
        "TOP_K = 10\r\n",
        "\r\n",
        "# Select MovieLens data size: 100k, 1m, 10m, or 20m\r\n",
        "MOVIELENS_DATA_SIZE = '100k'"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634740630000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the following settings work well for debugging locally on VM - change when running on a cluster\r\n",
        "# set up a giant single executor with many threads and specify memory cap\r\n",
        "spark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\")"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634740645979
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download the MovieLens dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "# Note: The DataFrame-based API for ALS currently only supports integers for user and item ids.\r\n",
        "schema = StructType(\r\n",
        "    (\r\n",
        "        StructField(\"UserId\", IntegerType()),\r\n",
        "        StructField(\"MovieId\", IntegerType()),\r\n",
        "        StructField(\"Rating\", FloatType()),\r\n",
        "        StructField(\"Timestamp\", LongType()),\r\n",
        "    )\r\n",
        ")\r\n",
        "\r\n",
        "data = movielens.load_spark_df(spark, size=MOVIELENS_DATA_SIZE, schema=schema)\r\n",
        "data.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 4.81k/4.81k [00:01<00:00, 4.62kKB/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+------+-------+------+---------+\n|UserId|MovieId|Rating|Timestamp|\n+------+-------+------+---------+\n|   196|    242|   3.0|881250949|\n|   186|    302|   3.0|891717742|\n|    22|    377|   1.0|878887116|\n|   244|     51|   2.0|880606923|\n|   166|    346|   1.0|886397596|\n|   298|    474|   4.0|884182806|\n|   115|    265|   2.0|881171488|\n|   253|    465|   5.0|891628467|\n|   305|    451|   3.0|886324817|\n|     6|     86|   3.0|883603013|\n|    62|    257|   2.0|879372434|\n|   286|   1014|   5.0|879781125|\n|   200|    222|   5.0|876042340|\n|   210|     40|   3.0|891035994|\n|   224|     29|   3.0|888104457|\n|   303|    785|   3.0|879485318|\n|   122|    387|   5.0|879270459|\n|   194|    274|   2.0|879539794|\n|   291|   1042|   4.0|874834944|\n|   234|   1184|   2.0|892079237|\n+------+-------+------+---------+\nonly showing top 20 rows\n\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634740658978
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Split the data using the Spark random splitter provided in utilities"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = spark_random_split(data, ratio=0.75, seed=123)\r\n",
        "print (\"N train\", train.cache().count())\r\n",
        "print (\"N test\", test.cache().count())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "N train 75018\nN test 24982\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634740666078
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Train the ALS model on the training data, and get the top-k recommendations for our testing data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "header = {\r\n",
        "    \"userCol\": \"UserId\",\r\n",
        "    \"itemCol\": \"MovieId\",\r\n",
        "    \"ratingCol\": \"Rating\",\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "als = ALS(\r\n",
        "    rank=10,\r\n",
        "    maxIter=15,\r\n",
        "    implicitPrefs=False,\r\n",
        "    regParam=0.05,\r\n",
        "    coldStartStrategy='drop',\r\n",
        "    nonnegative=False,\r\n",
        "    seed=42,\r\n",
        "    **header\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634740677966
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "with Timer() as train_time:\r\n",
        "    model = als.fit(train)\r\n",
        "\r\n",
        "print(\"Took {} seconds for training.\".format(train_time.interval))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Took 10.914644323000175 seconds for training.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634740697974
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with Timer() as test_time:\r\n",
        "\r\n",
        "    # Get the cross join of all user-item pairs and score them.\r\n",
        "    users = train.select('UserId').distinct()\r\n",
        "    items = train.select('MovieId').distinct()\r\n",
        "    user_item = users.crossJoin(items)\r\n",
        "    dfs_pred = model.transform(user_item)\r\n",
        "\r\n",
        "    # Remove seen items.\r\n",
        "    dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\r\n",
        "        train.alias(\"train\"),\r\n",
        "        (dfs_pred['UserId'] == train['UserId']) & (dfs_pred['MovieId'] == train['MovieId']),\r\n",
        "        how='outer'\r\n",
        "    )\r\n",
        "\r\n",
        "    top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.Rating\"].isNull()) \\\r\n",
        "        .select('pred.' + 'UserId', 'pred.' + 'MovieId', 'pred.' + \"prediction\")\r\n",
        "\r\n",
        "    # In Spark, transformations are lazy evaluation\r\n",
        "    # Use an action to force execute and measure the test time \r\n",
        "    top_all.cache().count()\r\n",
        "\r\n",
        "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Took 35.90560831200128 seconds for prediction.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634740740188
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_all.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+------+-------+----------+\n|UserId|MovieId|prediction|\n+------+-------+----------+\n|     1|    587| 4.1602826|\n|     1|    869| 2.7732863|\n|     1|   1208| 2.0333834|\n|     1|   1348| 1.0019257|\n|     1|   1357|0.94300246|\n|     1|   1677|  2.877732|\n|     2|     80| 2.3513849|\n|     2|    472| 2.5865319|\n|     2|    582| 3.9548612|\n|     2|    838| 0.9482963|\n|     2|    975| 3.1133537|\n|     2|   1260| 1.9871742|\n|     2|   1325| 1.2368053|\n|     2|   1381| 3.5477588|\n|     2|   1530| 2.0882902|\n|     3|     22| 3.1524532|\n|     3|     57|  3.698017|\n|     3|     89| 3.9733815|\n|     3|    367|  3.662905|\n|     3|   1091|  0.914447|\n+------+-------+----------+\nonly showing top 20 rows\n\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634740855136
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Evaluate how well ALS performs"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_eval = SparkRankingEvaluation(test, top_all, k = TOP_K, col_user=\"UserId\", col_item=\"MovieId\", \r\n",
        "                                    col_rating=\"Rating\", col_prediction=\"prediction\", \r\n",
        "                                    relevancy_method=\"top_k\")"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634740971062
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model:\\tALS\",\r\n",
        "      \"Top K:\\t%d\" % rank_eval.k,\r\n",
        "      \"MAP:\\t%f\" % rank_eval.map_at_k(),\r\n",
        "      \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\r\n",
        "      \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\r\n",
        "      \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), sep='\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model:\tALS\nTop K:\t10\nMAP:\t0.006527\nNDCG:\t0.051718\nPrecision@K:\t0.051274\nRecall@K:\t0.018840\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634741004135
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "# Generate predicted ratings.\r\n",
        "prediction = model.transform(test)\r\n",
        "prediction.cache().show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+------+-------+------+---------+----------+\n|UserId|MovieId|Rating|Timestamp|prediction|\n+------+-------+------+---------+----------+\n|   580|    148|   4.0|884125773| 3.4059546|\n|   406|    148|   3.0|879540276| 2.7134619|\n|   916|    148|   2.0|880843892|  2.224198|\n|   663|    148|   4.0|889492989| 2.7143621|\n|   330|    148|   4.0|876544781| 4.5232096|\n|   935|    148|   4.0|884472892| 4.3838587|\n|   308|    148|   3.0|887740788|  2.616949|\n|    20|    148|   5.0|879668713|   4.37212|\n|   923|    148|   4.0|880387474|  3.981858|\n|   455|    148|   3.0|879110346| 3.0764189|\n|    15|    148|   3.0|879456049| 2.9913845|\n|   374|    148|   4.0|880392992| 3.2223387|\n|   880|    148|   2.0|880167030| 2.8111978|\n|   677|    148|   4.0|889399265| 3.8451846|\n|    49|    148|   1.0|888068195| 1.3751596|\n|   244|    148|   2.0|880605071| 2.6781514|\n|    84|    148|   4.0|883452274|  3.672177|\n|   627|    148|   3.0|879530463| 2.6362073|\n|   434|    148|   3.0|886724797| 3.0973833|\n|   793|    148|   4.0|875104498| 2.2886577|\n+------+-------+------+---------+----------+\nonly showing top 20 rows\n\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634741916073
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_eval = SparkRatingEvaluation(test, prediction, col_user=\"UserId\", col_item=\"MovieId\", \r\n",
        "                                    col_rating=\"Rating\", col_prediction=\"prediction\")\r\n",
        "\r\n",
        "print(\"Model:\\tALS rating prediction\",\r\n",
        "      \"RMSE:\\t%f\" % rating_eval.rmse(),\r\n",
        "      \"MAE:\\t%f\" % rating_eval.mae(),\r\n",
        "      \"Explained variance:\\t%f\" % rating_eval.exp_var(),\r\n",
        "      \"R squared:\\t%f\" % rating_eval.rsquared(), sep='\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model:\tALS rating prediction\nRMSE:\t0.967434\nMAE:\t0.753340\nExplained variance:\t0.265916\nR squared:\t0.259532\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634742096149
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}